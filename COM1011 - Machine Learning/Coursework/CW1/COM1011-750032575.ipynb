{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSEWORK SPECIFICATION\n",
    "\n",
    "## COM1011 - Fundamentals of Machine Learning\n",
    "\n",
    "**Module Leader:** Chico Camargo\n",
    "\n",
    "**Academic Year:** 2025/26\n",
    "\n",
    "**Title:** Coursework 1\n",
    "\n",
    "**Submission deadline:** 3rd November 2025, 12:00pm(noon).\n",
    "\n",
    "This assessment contributes **30%** of the total module mark and assesses the following intended learning outcomes:\n",
    "\n",
    "1. Understanding and identifying the compromises and trade-offs that must be made when using a machine learning approach;\n",
    "2. Analysing problems from a data-centric point of view, choosing among a range of supervised and unsupervised machine learning techniques and using relevant software libraries to solve them\n",
    "3. Stating the importance and difficulty of establishing machine learning solutions; \n",
    "4. Using elementary python for implementing machine learning algorithms. \n",
    "5. Identifying the compromises that must be made when translating theory into practice; \n",
    "\n",
    "**This is an individual assessment** and you are reminded of the University's regulations on collaboration and plagiarism. You must avoid plagiarism, collusion, and any academic misconduct behaviours. Further details about academic honesty and plagiarism can be found at https://ele.exeter.ac.uk/course/view.php?id=1957."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________\n",
    "\n",
    "# What to submit\n",
    "\n",
    "You are required to submit your assignment **3rd November 2025 at 12:00pm(noon)**.\n",
    "\n",
    "Please do all your work in this Jupyter notebook. Make a separate cell for every few lines of code, and use separate cells for text, like this one.\n",
    "Save your file in the format `COM1011_STUDENTNUMBER.ipynb` and zip it.\n",
    "For example, if your student number is 12345678, save your coursework as `COM1011_12345678.ipynb`.\n",
    "Once you have done that, zip the file, producing a file called `COM1011_12345678.zip`. This is the file you will have to upload and submit to ELE.\n",
    "\n",
    "This assignment will also use three additional files, named `AmesHousingSimple.csv`, `mnist_train.csv`, and `mnist_test.csv`. Do not include them in the `COM1011_STUDENTNUMBER.zip` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer template\n",
    "\n",
    "Please use this notebook for your coursework. Feel free to add more cells for your code and answers, but try to stick to this format. This will make it easier to mark everyone's work fairly.\n",
    "\n",
    "___________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                 Version\n",
      "----------------------- -----------\n",
      "asttokens               3.0.0\n",
      "blinker                 1.9.0\n",
      "click                   8.3.0\n",
      "colorama                0.4.6\n",
      "comm                    0.2.3\n",
      "contourpy               1.3.3\n",
      "cycler                  0.12.1\n",
      "debugpy                 1.8.17\n",
      "decorator               5.2.1\n",
      "executing               2.2.1\n",
      "Flask                   3.1.2\n",
      "fonttools               4.60.1\n",
      "ipykernel               6.30.1\n",
      "ipython                 9.6.0\n",
      "ipython_pygments_lexers 1.1.1\n",
      "itsdangerous            2.2.0\n",
      "jedi                    0.19.2\n",
      "Jinja2                  3.1.6\n",
      "jupyter_client          8.6.3\n",
      "jupyter_core            5.8.1\n",
      "kiwisolver              1.4.9\n",
      "MarkupSafe              3.0.3\n",
      "matplotlib              3.10.7\n",
      "matplotlib-inline       0.1.7\n",
      "nest-asyncio            1.6.0\n",
      "numpy                   2.3.3\n",
      "packaging               25.0\n",
      "pandas                  2.3.3\n",
      "parso                   0.8.5\n",
      "pillow                  11.3.0\n",
      "pip                     25.2\n",
      "platformdirs            4.4.0\n",
      "prompt_toolkit          3.0.52\n",
      "psutil                  7.1.0\n",
      "pure_eval               0.2.3\n",
      "Pygments                2.19.2\n",
      "pyparsing               3.2.5\n",
      "python-dateutil         2.9.0.post0\n",
      "pytz                    2025.2\n",
      "pywin32                 311\n",
      "pyzmq                   27.1.0\n",
      "seaborn                 0.13.2\n",
      "setuptools              80.9.0\n",
      "six                     1.17.0\n",
      "stack-data              0.6.3\n",
      "tornado                 6.5.2\n",
      "traitlets               5.14.3\n",
      "typing_extensions       4.15.0\n",
      "tzdata                  2025.2\n",
      "wcwidth                 0.2.14\n",
      "Werkzeug                3.1.3\n",
      "wheel                   0.45.1\n"
     ]
    }
   ],
   "source": [
    "# Run this cell so we know the versions of all libraries in your computer\n",
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A - AmesHousing Dataset: Linear Regression Analysis\n",
    "\n",
    "This part of the assignment is based on the AmesHousing Dataset, which contains information about various features of houses.\n",
    "It is  real estate dataset from Ames, Iowa (USA) compiled by Dean De Cock for teaching data science. About 2,930 residential property sales with 80–82 features describing each house.\n",
    "The original Ames dataset has over 80 features (such as lot size, number of rooms, garage details, neighborhood, etc.). To keep things clear and focused, we have reduced it to 7 numeric features + 1 target variable.\n",
    "Target feature (what we predict): SalePrice (final sale price in USD).\n",
    "\n",
    "\n",
    "\n",
    "____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation (5 points)\n",
    "\n",
    "1.1. Load the AmesHousingsimple.csv dataset, display the first 5 rows, and report the dataset’s shape and missing value statistics. (1 point)\n",
    "\n",
    "1.2. Visualize the dataset:  Create scatterplots to explore the relationship between features and the target variable SalePrice. Here we want to plot the scatterplots Gr Liv Area VS SalePrice(1 points).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers here\n",
    "import pandas as pd\n",
    "\n",
    "# Load the csv file into a Pandas DataFrame\n",
    "df = pd.DataFrame(\"AmesHousingSimple.csv\")\n",
    "\n",
    "# Display the first 5 rows of the data set\n",
    "print(df.head())\n",
    "\n",
    "# Display the data sets shape and null value stats\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3. For each column, report how many values are missing. Which feature has the most missing values? （1 point）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4. Try one imputation strategies for missing values (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5. Calculate the correlation matrix between all numeric features in the dataset and plot the correlation matrix as a heatmap to visualize relationships between features and SalePrice.(1 point)(1 points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear Regression (20 points)\n",
    "\n",
    "Implement a linear regression model using only the 'Overall Qual', 'Year Built' and 'Bedroom AbvGr ' features to predict 'SalePrice'.\n",
    "2.1 Separate the dataset into features (X) and target (y = SalePrice). Split into training and testing sets (80/20 split). (2 points)\n",
    "\n",
    "2.2. Fit the model on the training data and make predictions on the test data. (4 points)\n",
    "\n",
    "2.3. Calculate and print the Mean Squared Error (MSE) and R-squared score for both training and test sets. (3 points)\n",
    "\n",
    "2.4. Make a scatterplot comparing the actual 'SalePrice' values vs. the predicted 'SalePrice' values. (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5.  Implement a linear regression model using all features. (3 points).\n",
    "\n",
    "2.6.  Make a scatterplot comparing the actual 'SalePrice' values vs. the predicted 'SalePrice' values. (2 points).\n",
    "\n",
    "2.7.  Compare its performance with the simple linear regression model using the metrics discussed so far. Which one does better? Print the result. (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "\n",
    "## 3. Comparing Linear Regression with Polynomial Regression (15 points)\n",
    "\n",
    "3.1. Implement a linear regression model and a polynomial regression model with degree 2 (a quadratic equation) using the 'Gr Liv Area' feature to predict 'SalePrice'. Do a train-test split, and compare how they perform by printing off their R² values and MSE on both the train and test data. (4 points)\n",
    "\n",
    "3.2.  Create a scatter plot showing the predictions of both linear and polynomial models on the same graph, against the actual data. (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3. Implement polynomial regression with degrees 1, 2, 3, and 4 using ALL features. First, plot the fitted regression curves for each degree on top of the data. Then, perform cross-validation and plot the mean squared error (MSE) for each degree to compare their performances. (4 points)\n",
    "\n",
    "Hint: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4. Discuss the trade-offs between model complexity and performance. Consider concepts such as overfitting, underfitting, and the bias-variance tradeoff. (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers here (double click to edit this cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Selection (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1. Looking at the performance of using selected features and full features in the linear logic regression tasks, which model performs better and why? Compare the Polynomial Regression models trained by only one feature and full features, which model performs better, and what might explain the difference in performance? (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers here (double click to edit this cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2. Discuss the impact of feature selection on model performance and interpretability. (5 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers here (double click to edit this cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________\n",
    "\n",
    "# Part B - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Preparation and Exploration (5 points)\n",
    "\n",
    "5.1\tLoad the MNIST dataset (`mnist_train.csv` and `mnist_test.csv`) using the pandas library. (1 point)\n",
    "\n",
    "5.2\tSeparate features (X) and labels (y) for both train and test data. (1 point) Note: In this dataset, the first column corresponds to the label (digit 0–9), and the remaining 784 columns are pixel features.\n",
    "\n",
    "5.3\tNormalize values of the features (X) so they are between 0 and 1. (1 point)\n",
    "\n",
    "5.4 The input variables (X) should be 784-dimensional vectors. These actually represent 28x28 pixel images[1], but with all pixels represented as individual features. With that in mind, take 5 random data points (i.e. 5 random rows of the dataset), reshape them[2] from 784-dimensional vectors into 28x28 matrices, and display them (2 points).\n",
    "\n",
    "[1] - https://en.wikipedia.org/wiki/MNIST_database\n",
    "\n",
    "[2] - https://numpy.org/doc/2.0/reference/generated/numpy.reshape.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Classification using a Perceptron (15 points)\n",
    "\n",
    "We will use the Perceptron classifier to distinguish between digit '0' and digit '1'. Use only the subset of the data corresponding to these two digits. \n",
    "\n",
    "6.1. \tTrain the Perceptron on the training data for this binary classification task. (3 points)\n",
    "\n",
    "6.2. \tEvaluate the Perceptron on the test set. Print out the test accuracy. (3 points)\n",
    "\n",
    "6.3. \tPlot the confusion matrix showing how well the classifier performs on the test set for this binary task. (3 points)\n",
    "\n",
    "6.4. Calculate and print the precision, recall, and F1 score for the Perceptron classifier. (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 6.5 Implement a multi-class Perceptron classifier for all 10 digits. Train and evaluate it on the full dataset. Print the overall accuracy. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 6.6 Plot a confusion matrix for your multi-class classifier. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Classification with Logistic Regression (15 points)\n",
    "\n",
    "Now we will implement a Logistic Regression classifier for the same binary classification task as with the perceptron.\n",
    "\n",
    "7.1. \tTrain the Logistic Regression model on the training data for this binary classification task. (3 points)\n",
    "\n",
    "7.2. \tEvaluate the Logistic Regression model on the test set. Print out the test accuracy. (3 points)\n",
    "\n",
    "7.3. \tPlot the confusion matrix for the Logistic Regression model on this binary task. (3 points)\n",
    "\n",
    "7.4. \tCalculate and print the precision, recall, and F1 score for the Logistic Regression classifier (3 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.5 Implement a multi-class Logistic Regression classifier for all 10 digits. Train and evaluate it on the full dataset. Print the overall accuracy. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 7.6 Plot the confusion matrix for the multi-class Logistic Regression classifier. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Comparison and Analysis (7 points)\n",
    "\n",
    "8.1. For the multi-class Logistic Regression model, identify the three digits that are most frequently misclassified (i.e. classified wrong). Using the same `numpy.reshape` code as in question 5.4, display example images of these misclassified data points (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.2. Compare the performance of the Perceptron and Logistic Regression models on the binary classification and multi-class tasks. Which performed better? Explain why you think this is the case (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers here (double click to edit this cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Understanding Machine Learning (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.1. How might you modify the input data or feature representation to potentially improve the performance of these models on the MNIST dataset? Suggest at least two specific techniques (4 points)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers here (double click to edit this cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.2. Explain the importance of the train-test split in this context. What might happen if you trained and evaluated the models on the entire dataset without splitting?  (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers here (double click to edit this cell)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
